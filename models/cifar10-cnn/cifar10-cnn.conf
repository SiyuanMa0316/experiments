network {
  name = "keras-example"
  input_rows = 32
  input_cols = 32
  input_height = 3

  layer conv0 {
    type = CONVOLUTION
    activation = RELU
    convolution_param {
      num_output = 32
      kernel_size = 3
      stride = 1
      padding = SAME
    }
  }

  layer bn0 {
    type = BATCH_NORM
  }

  layer conv1 {
    type = CONVOLUTION
    activation = RELU
    convolution_param {
      num_output = 32
      kernel_size = 3
      stride = 1
      padding = SAME
    }
  }

  layer pool1 {
    type = POOLING
    pooling_param {
      pool = MAX
      size = 2
      stride = 2
    }
  }

  layer bn1 {
    type = BATCH_NORM
  }

  layer conv2 {
    type = CONVOLUTION
    activation = RELU
    convolution_param {
      num_output = 64
      kernel_size = 3
      stride = 1
      padding = SAME
    }
  }

  layer conv3 {
    type = CONVOLUTION
    activation = RELU
    convolution_param {
      num_output = 64
      kernel_size = 3
      stride = 1
      padding = SAME
    }
  }

  layer pool2 {
    type = POOLING
    pooling_param {
      pool = MAX
      size = 2
      stride = 2
    }
  }

  layer bn2 {
    type = BATCH_NORM
  }

  layer fc2 {
    type = INNER_PRODUCT
    activation = RELU
    inner_product_param {
      num_output = 512
    }
  }

  layer fc3 {
    type = INNER_PRODUCT
    inner_product_param {
      num_output = 10
    }
  }
}

device {
  cpu_default_offload = DMA
  cpu_activation_func_offload = DMA
  cpu_pooling_offload = DMA
  weights_load_policy = DMA_ALWAYS
  use_hw_activation_func = true
  use_hw_batch_norm = true
  use_hw_pooling = true
  use_pipelined_dma = true
}

sampling_param {
  standard_conv_num_filters = 2
  fc_num_neurons = 0
  smv_conv_inner_iters = 1
}
